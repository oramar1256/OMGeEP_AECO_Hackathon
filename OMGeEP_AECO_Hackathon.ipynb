{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e7383a-d9b6-4083-aa7f-83b020bce89c",
   "metadata": {},
   "source": [
    "# OMGeEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "572fc01b-c6a3-4b7b-9008-700243848a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%git` not found.\n"
     ]
    }
   ],
   "source": [
    "%git config --global user.email \"oramar1256@gmail.com\"\n",
    "%git config --global user.name \"oramar1256\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6389f2fc-0d41-40e1-b312-e31a75477049",
   "metadata": {},
   "source": [
    "# Download dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3e596609-0e5c-4259-8842-325ff70bbb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.13/site-packages (4.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.13/site-packages (1.7.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.13/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.13/site-packages (2.2.6)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.13/site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.13/site-packages (from lightgbm) (1.16.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting iterative-stratification\n",
      "  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.13/site-packages (from iterative-stratification) (2.2.6)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.13/site-packages (from iterative-stratification) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.13/site-packages (from iterative-stratification) (1.7.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.13/site-packages (from scikit-learn->iterative-stratification) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.13/site-packages (from scikit-learn->iterative-stratification) (3.6.0)\n",
      "Downloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\n",
      "Installing collected packages: iterative-stratification\n",
      "Successfully installed iterative-stratification-0.1.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting shap\n",
      "  Downloading shap-0.48.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.13/site-packages (from shap) (2.2.6)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.13/site-packages (from shap) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.13/site-packages (from shap) (1.7.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.13/site-packages (from shap) (2.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /opt/conda/lib/python3.13/site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.13/site-packages (from shap) (25.0)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba>=0.54 in /opt/conda/lib/python3.13/site-packages (from shap) (0.61.2)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.13/site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.13/site-packages (from shap) (4.15.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/conda/lib/python3.13/site-packages (from numba>=0.54->shap) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.13/site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.13/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.13/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.13/site-packages (from scikit-learn->shap) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.13/site-packages (from scikit-learn->shap) (3.6.0)\n",
      "Downloading shap-0.48.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: slicer, shap\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [shap][32m1/2\u001b[0m [shap]\n",
      "\u001b[1A\u001b[2KSuccessfully installed shap-0.48.0 slicer-0.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm scikit-learn pandas numpy joblib\n",
    "%pip install iterative-stratification\n",
    "%pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c34a2a-3329-4861-b036-7f752d62577c",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fc9fce67-4bca-4453-a71b-b5dc12ca2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import f1_score, hamming_loss, roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Optional: iterative stratification\n",
    "try:\n",
    "    from iterstrat.ml_stratifiers import iterative_train_test_split\n",
    "    ITERATIVE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ITERATIVE_AVAILABLE = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e2e19-5434-471d-8ffe-b86b48f18620",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7a8c096e-21cd-4b3a-a9f0-8a5c832fd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'ifbdata/atlanteco_hack/OMGeEP/output_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf25c6-2772-48a6-b4bf-aaee40e147f8",
   "metadata": {},
   "source": [
    "# Read genomic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682ef88-3fb2-425c-b5c1-8dfc15d597eb",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2a625008-b20f-4735-871d-840673f78eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_gene_abundances(df:pd.DataFrame, method:str='tss', id_col:str=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize gene abundance data for comparison between samples.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with gene IDs in first column and samples as remaining columns\n",
    "    method : str, default 'tss'\n",
    "        Normalization method:\n",
    "        - 'tss': Total Sum Scaling (relative abundance, sums to 1)\n",
    "        - 'tss_percent': Total Sum Scaling as percentages (sums to 100)\n",
    "        - 'z_score': Z-score normalization (mean=0, std=1)\n",
    "        - 'min_max': Min-max scaling (0 to 1 range)\n",
    "        - 'log_tss': Log-transformed TSS (log10(TSS + pseudocount))\n",
    "        - 'clr': Centered Log Ratio transformation\n",
    "    id_col : str, optional\n",
    "        Name of ID column. If None, assumes first column is ID\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Normalized DataFrame with same structure as input\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    df_norm = df.copy()\n",
    "    \n",
    "    # Identify ID column\n",
    "    if id_col is None:\n",
    "        id_col = df.columns[0]\n",
    "    \n",
    "    # Get sample columns (all except ID column)\n",
    "    sample_cols = [col for col in df.columns if col != id_col]\n",
    "    \n",
    "    # Extract abundance matrix\n",
    "    abundance_matrix = df_norm[sample_cols].values\n",
    "    \n",
    "    if method == 'tss':\n",
    "        # Total Sum Scaling - convert to relative abundances\n",
    "        col_sums = abundance_matrix.sum(axis=0)\n",
    "        normalized_matrix = abundance_matrix / col_sums\n",
    "        \n",
    "    elif method == 'tss_percent':\n",
    "        # Total Sum Scaling as percentages\n",
    "        col_sums = abundance_matrix.sum(axis=0)\n",
    "        normalized_matrix = (abundance_matrix / col_sums) * 100\n",
    "        \n",
    "    elif method == 'z_score':\n",
    "        # Z-score normalization (standardization)\n",
    "        normalized_matrix = (abundance_matrix - abundance_matrix.mean(axis=0)) / abundance_matrix.std(axis=0)\n",
    "        \n",
    "    elif method == 'min_max':\n",
    "        # Min-max scaling to [0, 1] range\n",
    "        min_vals = abundance_matrix.min(axis=0)\n",
    "        max_vals = abundance_matrix.max(axis=0)\n",
    "        normalized_matrix = (abundance_matrix - min_vals) / (max_vals - min_vals)\n",
    "        \n",
    "    elif method == 'log_tss':\n",
    "        # Log-transformed TSS (common in metagenomics)\n",
    "        col_sums = abundance_matrix.sum(axis=0)\n",
    "        tss_matrix = abundance_matrix / col_sums\n",
    "        # Add small pseudocount to avoid log(0)\n",
    "        pseudocount = 1e-10\n",
    "        normalized_matrix = np.log10(tss_matrix + pseudocount)\n",
    "        \n",
    "    elif method == 'clr':\n",
    "        # Centered Log Ratio transformation\n",
    "        # Add small pseudocount to avoid log(0)\n",
    "        pseudocount = 1e-10\n",
    "        log_matrix = np.log(abundance_matrix + pseudocount)\n",
    "        geometric_means = log_matrix.mean(axis=0)\n",
    "        normalized_matrix = log_matrix - geometric_means\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown normalization method: {method}\")\n",
    "    \n",
    "    # Replace the sample columns with normalized values\n",
    "    df_norm[sample_cols] = normalized_matrix\n",
    "    \n",
    "    return df_norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "16432a7e-4bf4-4409-a836-cc0a29d186a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_genomic_data(genomic_data_path:str, rows_to_skip:int=7) -> pd.DataFrame:\n",
    "\n",
    "    # read df\n",
    "    gen_df = pd.read_csv(genomic_data_path, sep='\\t')\n",
    "    # rename gene id row to ID\n",
    "    gen_df.rename(columns={'Unnamed: 0':'ID'}, inplace=True)\n",
    "    # remove metaparams\n",
    "    gen_df = gen_df.iloc[rows_to_skip:]\n",
    "    # convert NAN to 0\n",
    "    gen_df.fillna(0, inplace=True)\n",
    "    # change values to numeric (expect geneID)\n",
    "    sample_cols = gen_df.columns.drop('ID')\n",
    "    gen_df[sample_cols] = gen_df[sample_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Remove samples with no genes\n",
    "    # 1. Calculate column sums for sample columns\n",
    "    col_sums = gen_df[sample_cols].sum()\n",
    "    # 2. Find columns with zero sum\n",
    "    zero_sum_cols = col_sums[col_sums == 0].index.tolist()\n",
    "    # 3. Remove zero-sum columns\n",
    "    if zero_sum_cols:\n",
    "        gen_df = gen_df.drop(columns=zero_sum_cols)\n",
    "\n",
    "    # reset index\n",
    "    gen_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # normalize the results per sample\n",
    "    gen_df_normalized = normalize_gene_abundances(gen_df, method='tss', id_col='ID')\n",
    "\n",
    "    # return normalized df\n",
    "    return gen_df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b755b0a-6bca-4db8-950d-78619236796a",
   "metadata": {},
   "source": [
    "## Running genomic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0b725ddc-2185-4ec3-8ce4-5077d300c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_gen_df = read_genomic_data(genomic_data_path='ifbdata/atlanteco_hack/MetaGenomics/BenguelaCurrent_GeneAb/BenguelaCurrent_ffn_GeneAb_T.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c697af46-ab65-42c0-b525-835f9d546670",
   "metadata": {},
   "outputs": [],
   "source": [
    "wedd_gen_df = read_genomic_data(genomic_data_path='ifbdata/atlanteco_hack/MetaGenomics/WeddellSea_GeneAb/WeddellSea_ffn_GeneAb_T.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd9da4-d6f2-4be7-b290-7d82294068bf",
   "metadata": {},
   "source": [
    "# Read environmental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972dcbea-6018-41ee-92fe-a47b2ee486c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1d50aa9-0694-4414-86ad-28e312342858",
   "metadata": {},
   "source": [
    "# Read Proteomics data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56059c00-3993-4d73-8267-96f76c5f93fe",
   "metadata": {},
   "source": [
    "# Read Metabolomic data (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e222e75c-8192-41de-9e48-f49437a3a62b",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7475e099-e649-46d3-9267-5d269d0edd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_relevant_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Keep only columns starting with 'featureId' or 'SAMEA'.\n",
    "    \"\"\"\n",
    "    return df.loc[:, df.columns.str.startswith(('featureId', 'SAMEA'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1cc80d65-1f8f-433c-82e5-52ca87602535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_samea_column_names(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove the trailing '_RX' from SAMEA column names.\n",
    "    E.g., SAMEA123456_R01_R2 -> SAMEA123456_R01\n",
    "    \"\"\"\n",
    "    rename_map = {\n",
    "        col: re.sub(r'(SAMEA\\d+_R\\d+)_R\\d+$', r'\\1', col)\n",
    "        if col.startswith('SAMEA') else col\n",
    "        for col in df.columns\n",
    "    }\n",
    "    return df.rename(columns=rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "19dece8a-8641-454c-8a43-5f89fed618ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_samea_columns(df: pd.DataFrame, threshold: float = 2e4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Group columns with the same SAMEAXXXXXX prefix:\n",
    "      - If any column in the group > threshold â†’ grouped value = 1\n",
    "      - If all columns in the group â‰¤ threshold â†’ grouped value = 0\n",
    "\n",
    "    The grouped columns will replace the original SAMEA columns.\n",
    "    \"\"\"\n",
    "    # Map each SAMEA column to its base prefix (SAMEAXXXXXX)\n",
    "    prefix_map = {\n",
    "        col: re.match(r'(SAMEA\\d+)', col).group(1)\n",
    "        if col.startswith('SAMEA') else col\n",
    "        for col in df.columns\n",
    "    }\n",
    "\n",
    "    result = df.copy()\n",
    "    for prefix in set(prefix_map.values()):\n",
    "        if prefix.startswith('SAMEA'):\n",
    "            same_cols = [col for col, pfx in prefix_map.items() if pfx == prefix]\n",
    "\n",
    "            # ðŸ”¹ Ensure these columns are numeric (convert strings â†’ numbers, non-numeric â†’ NaN)\n",
    "            numeric_block = df[same_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # âœ… Compute on numeric_block, not df\n",
    "            result[prefix] = (numeric_block > threshold).any(axis=1).astype(int)\n",
    "\n",
    "            # Drop original group columns\n",
    "            result = result.drop(columns=same_cols)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f0511265-6b33-483a-832f-da91bd8df6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metabolomic_data(metabolome_data_path:str, threshold: float = 2e4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Full pipeline:\n",
    "      1. Filter columns\n",
    "      2. Clean SAMEA column names\n",
    "      3. Group SAMEA columns using threshold logic\n",
    "    \"\"\"\n",
    "    metabolome_df = pd.read_csv(metabolome_data_path, sep='\\t')\n",
    "    metabolome_df.drop(metabolome_df.tail(1).index,inplace=True) # drop last row\n",
    "    metabolome_df = filter_relevant_columns(metabolome_df)\n",
    "    metabolome_df = clean_samea_column_names(metabolome_df)\n",
    "    metabolome_df = group_samea_columns(metabolome_df, threshold=threshold)\n",
    "    return metabolome_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f5c02-77d5-42b0-a0a6-264f7ee0eed2",
   "metadata": {},
   "source": [
    "## Running metabolomic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2d74ca0a-38e9-4c71-9cd4-d3510e4966a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolome_path = 'ifbdata/atlanteco_hack/MetaMetabolomics/1_Feature_table_univariate_analysis_hackathon'\n",
    "\n",
    "processed_metabolomic_data = process_metabolomic_data(metabolome_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e770466a-4c7e-46ca-b11a-7e4db05aab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    651561\n",
      "0     44715\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "processed_metabolomic_data.head()\n",
    "sample_cols = [col for col in processed_metabolomic_data.columns if col != 'featureId']\n",
    "counts = processed_metabolomic_data[sample_cols].stack().value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4d061fdb-447e-4895-9c32-7f7bdb0a1938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_metabolomic_data['featureId'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b5de33-3050-45df-affa-6d6ec6b27382",
   "metadata": {},
   "source": [
    "# Next section (template header)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
